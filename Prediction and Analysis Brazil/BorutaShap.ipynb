{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41af53f-51fb-4147-b3df-2d666eb8d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, IsolationForest\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.sparse import issparse\n",
    "from scipy.stats import binomtest, ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class BorutaShap:\n",
    "\n",
    "    \"\"\"\n",
    "    BorutaShap is a wrapper feature selection method built on the foundations of both the SHAP and Boruta algorithms.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model=None, importance_measure='Shap',\n",
    "                classification=True, percentile=100, pvalue=0.05):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: Model Object\n",
    "            If no model specified then a base Random Forest will be returned otherwise the specifed model will\n",
    "            be returned.\n",
    "\n",
    "        importance_measure: String\n",
    "            Which importance measure too use either Shap or Gini/Gain\n",
    "\n",
    "        classification: Boolean\n",
    "            if true then the problem is either a binary or multiclass problem otherwise if false then it is regression\n",
    "\n",
    "        percentile: Int\n",
    "            An integer ranging from 0-100 it changes the value of the max shadow importance values. Thus, lowering its value\n",
    "            would make the algorithm more lenient.\n",
    "\n",
    "        p_value: float\n",
    "            A float used as a significance level again if the p-value is increased the algorithm will be more lenient making it smaller\n",
    "            would make it more strict also by making the model more strict could impact runtime making it slower. As it will be less likley\n",
    "            to reject and accept features.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.importance_measure = importance_measure\n",
    "        self.percentile = percentile\n",
    "        self.pvalue = pvalue\n",
    "        self.classification = classification\n",
    "        self.model = model\n",
    "        self.check_model()\n",
    "\n",
    "    @classmethod\n",
    "    def _get_param_names(cls):\n",
    "        \"\"\"Get parameter names for the estimator\"\"\"\n",
    "        # fetch the constructor or the original constructor before\n",
    "        # deprecation wrapping if any\n",
    "        init = getattr(cls.__init__, \"deprecated_original\", cls.__init__)\n",
    "        if init is object.__init__:\n",
    "            # No explicit constructor to introspect\n",
    "            return []\n",
    "\n",
    "        # introspect the constructor arguments to find the model parameters\n",
    "        # to represent\n",
    "        init_signature = inspect.signature(init)\n",
    "        # Consider the constructor parameters excluding 'self'\n",
    "        parameters = [\n",
    "            p\n",
    "            for p in init_signature.parameters.values()\n",
    "            if p.name != \"self\" and p.kind != p.VAR_KEYWORD\n",
    "        ]\n",
    "        for p in parameters:\n",
    "            if p.kind == p.VAR_POSITIONAL:\n",
    "                raise RuntimeError(\n",
    "                    \"scikit-learn estimators should always \"\n",
    "                    \"specify their parameters in the signature\"\n",
    "                    \" of their __init__ (no varargs).\"\n",
    "                    \" %s with constructor %s doesn't \"\n",
    "                    \" follow this convention.\" % (cls, init_signature)\n",
    "                )\n",
    "        # Extract and sort argument names excluding 'self'\n",
    "        return sorted([p.name for p in parameters])\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"\n",
    "        Get parameters for this estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        deep : bool, default=True\n",
    "            If True, will return the parameters for this estimator and\n",
    "            contained subobjects that are estimators.\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict\n",
    "            Parameter names mapped to their values.\n",
    "        \"\"\"\n",
    "        out = dict()\n",
    "        for key in self._get_param_names():\n",
    "            value = getattr(self, key)\n",
    "            if deep and hasattr(value, \"get_params\") and not isinstance(value, type):\n",
    "                deep_items = value.get_params().items()\n",
    "                out.update((key + \"__\" + k, val) for k, val in deep_items)\n",
    "            out[key] = value\n",
    "        return out\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Set the parameters of this estimator.\n",
    "        The method works on simple estimators as well as on nested objects\n",
    "        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
    "        parameters of the form ``<component>__<parameter>`` so that it's\n",
    "        possible to update each component of a nested object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        **params : dict\n",
    "            Estimator parameters.\n",
    "        Returns\n",
    "        -------\n",
    "        self : estimator instance\n",
    "            Estimator instance.\n",
    "        \"\"\"\n",
    "        if not params:\n",
    "            # Simple optimization to gain speed (inspect is slow)\n",
    "            return self\n",
    "        valid_params = self.get_params(deep=True)\n",
    "\n",
    "        nested_params = defaultdict(dict)  # grouped by prefix\n",
    "        for key, value in params.items():\n",
    "            key, delim, sub_key = key.partition(\"__\")\n",
    "            if key not in valid_params:\n",
    "                local_valid_params = self._get_param_names()\n",
    "                raise ValueError(\n",
    "                    f\"Invalid parameter {key!r} for estimator {self}. \"\n",
    "                    f\"Valid parameters are: {local_valid_params!r}.\"\n",
    "                )\n",
    "\n",
    "            if delim:\n",
    "                nested_params[key][sub_key] = value\n",
    "            else:\n",
    "                setattr(self, key, value)\n",
    "                valid_params[key] = value\n",
    "\n",
    "        for key, sub_params in nested_params.items():\n",
    "            valid_params[key].set_params(**sub_params)\n",
    "\n",
    "        return \n",
    "\n",
    "\n",
    "    def check_model(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Checks that a model object has been passed as a parameter when intiializing the BorutaShap class.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Model Object\n",
    "            If no model specified then a base Random Forest will be returned otherwise the specifed model will\n",
    "            be returned.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AttirbuteError\n",
    "             If the model object does not have the required attributes.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        check_fit = hasattr(self.model, 'fit')\n",
    "        check_predict_proba = hasattr(self.model, 'predict')\n",
    "\n",
    "        try:\n",
    "            check_feature_importance = hasattr(self.model, 'feature_importances_')\n",
    "\n",
    "        except:\n",
    "            check_feature_importance = True\n",
    "\n",
    "\n",
    "        if self.model is None:\n",
    "\n",
    "            if self.classification:\n",
    "                self.model = RandomForestClassifier()\n",
    "            else:\n",
    "                self.model = RandomForestRegressor()\n",
    "\n",
    "        elif check_fit is False and check_predict_proba is False:\n",
    "            raise AttributeError('Model must contain both the fit() and predict() methods')\n",
    "\n",
    "        elif check_feature_importance is False and self.importance_measure == 'gini':\n",
    "            raise AttributeError('Model must contain the feature_importances_ method to use Gini try Shap instead')\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def check_X(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Checks that the data passed to the BorutaShap instance is a pandas Dataframe\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Datframe\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AttirbuteError\n",
    "             If the data is not of the expected type.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(self.X, pd.DataFrame) is False:\n",
    "            raise AttributeError('X must be a pandas Dataframe')\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def missing_values_y(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Checks for missing values in target variable.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Boolean\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AttirbuteError\n",
    "             If data is not in the expected format.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(self.y, pd.Series) or isinstance(self.y, pd.DataFrame):\n",
    "            return self.y.isnull().any().any()\n",
    "\n",
    "        elif isinstance(self.y, np.ndarray):\n",
    "            return np.isnan(self.y).any()\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('Y must be a pandas Dataframe, Series, or a numpy array')\n",
    "\n",
    "\n",
    "    def check_missing_values(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Checks for missing values in the data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Boolean\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AttirbuteError\n",
    "             If there are missing values present.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        X_missing = self.X.isnull().any().any()\n",
    "        Y_missing = self.missing_values_y()\n",
    "\n",
    "        models_to_check = ('xgb', 'catboost', 'lgbm', 'lightgbm')\n",
    "\n",
    "        model_name = str(type(self.model)).lower()\n",
    "        if X_missing or Y_missing:\n",
    "\n",
    "            if any([x in model_name for x in models_to_check]):\n",
    "                print('Warning there are missing values in your data !')\n",
    "\n",
    "            else:\n",
    "                raise ValueError('There are missing values in your Data')\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def Check_if_chose_train_or_test_and_train_model(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Decides to fit the model to either the training data or the test/unseen data a great discussion on the\n",
    "        differences can be found here.\n",
    "\n",
    "        https://slds-lmu.github.io/iml_methods_limitations/pfi-data.html\n",
    "\n",
    "        \"\"\"\n",
    "        if self.stratify is not None and not self.classification:\n",
    "            raise ValueError('Cannot take a strtified sample from continuous variable please bucket the variable and try again !')\n",
    "\n",
    "\n",
    "        if self.train_or_test.lower() == 'test':\n",
    "            # keeping the same naming convenetion as to not add complexit later on\n",
    "            self.X_boruta_train, self.X_boruta_test, self.y_train, self.y_test, self.w_train, self.w_test = train_test_split(self.X_boruta,\n",
    "                                                                                                                                self.y,\n",
    "                                                                                                                                self.sample_weight,\n",
    "                                                                                                                                test_size=0.3,\n",
    "                                                                                                                                random_state=self.random_state,\n",
    "                                                                                                                                stratify=self.stratify)\n",
    "            self.Train_model(self.X_boruta_train, self.y_train, sample_weight = self.w_train)\n",
    "\n",
    "        elif self.train_or_test.lower() == 'train':\n",
    "            # model will be trained and evaluated on the same data\n",
    "            self.Train_model(self.X_boruta, self.y, sample_weight = self.sample_weight)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('The train_or_test parameter can only be \"train\" or \"test\"')\n",
    "\n",
    "\n",
    "\n",
    "    def Train_model(self, X, y, sample_weight = None):\n",
    "\n",
    "        \"\"\"\n",
    "        Trains Model also checks to see if the model is an instance of catboost as it needs extra parameters\n",
    "        also the try except is for models with a verbose statement\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: Dataframe\n",
    "            A pandas dataframe of the features.\n",
    "\n",
    "        y: Series/ndarray\n",
    "            A pandas series or numpy ndarray of the target\n",
    "\n",
    "        sample_weight: Series/ndarray\n",
    "            A pandas series or numpy ndarray of the sample weights\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        fitted model object\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if 'catboost' in str(type(self.model)).lower():\n",
    "            self.model.fit(X, y, sample_weight = sample_weight, cat_features = self.X_categorical,  verbose=False)\n",
    "\n",
    "        else:\n",
    "\n",
    "            try:\n",
    "                self.model.fit(X, y, sample_weight = sample_weight, verbose=False)\n",
    "\n",
    "            except:\n",
    "                self.model.fit(X, y, sample_weight = sample_weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y, sample_weight = None, n_trials = 20, random_state=0, sample=False,\n",
    "            train_or_test = 'test', normalize=True, verbose=True, stratify=None):\n",
    "\n",
    "        \"\"\"\n",
    "        The main body of the program this method it computes the following\n",
    "\n",
    "        1. Extend the information system by adding copies of all variables (the information system\n",
    "        is always extended by at least 5 shadow attributes, even if the number of attributes in\n",
    "        the original set is lower than 5).\n",
    "\n",
    "        2. Shuffle the added attributes to remove their correlations with the response.\n",
    "\n",
    "        3. Run a random forest classifier on the extended information system and gather the\n",
    "        Z scores computed.\n",
    "\n",
    "        4. Find the maximum Z score among shadow attributes (MZSA), and then assign a hit to\n",
    "        every attribute that scored better than MZSA.\n",
    "\n",
    "        5. For each attribute with undetermined importance perform a two-sided test of equality\n",
    "        with the MZSA.\n",
    "\n",
    "        6. Deem the attributes which have importance significantly lower than MZSA as ‘unimportant’\n",
    "        and permanently remove them from the information system.\n",
    "\n",
    "        7. Deem the attributes which have importance significantly higher than MZSA as ‘important’.\n",
    "\n",
    "        8. Remove all shadow attributes.\n",
    "\n",
    "        9. Repeat the procedure until the importance is assigned for all the attributes, or the\n",
    "        algorithm has reached the previously set limit of the random forest runs.\n",
    "\n",
    "        10. Stores results.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: Dataframe\n",
    "            A pandas dataframe of the features.\n",
    "\n",
    "        y: Series/ndarray\n",
    "            A pandas series or numpy ndarray of the target\n",
    "\n",
    "        sample_weight: Series/ndarray\n",
    "            A pandas series or numpy ndarray of the sample weight of the observations (optional)\n",
    "\n",
    "        random_state: int\n",
    "            A random state for reproducibility of results\n",
    "\n",
    "        Sample: Boolean\n",
    "            if true then a rowise sample of the data will be used to calculate the feature importance values\n",
    "\n",
    "        sample_fraction: float\n",
    "            The sample fraction of the original data used in calculating the feature importance values only\n",
    "            used if Sample==True.\n",
    "\n",
    "        train_or_test: string\n",
    "            Decides whether the feature importance should be calculated on out of sample data see the dicussion here.\n",
    "            https://compstat-lmu.github.io/iml_methods_limitations/pfi-data.html#introduction-to-test-vs.training-data\n",
    "\n",
    "        normalize: boolean\n",
    "            if true the importance values will be normalized using the z-score formula\n",
    "\n",
    "        verbose: Boolean\n",
    "            a flag indicator to print out all the rejected or accepted features.\n",
    "\n",
    "        stratify: array\n",
    "            allows the train test splits to be stratified based on given values.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(len(X))\n",
    "        np.random.seed(random_state)\n",
    "        self.starting_X = X.copy()\n",
    "        self.X = X.copy()\n",
    "        self.y = y.copy()\n",
    "        self.sample_weight = sample_weight.copy()\n",
    "        self.n_trials = n_trials\n",
    "        self.random_state = random_state\n",
    "        self.ncols = self.X.shape[1]\n",
    "        self.all_columns = self.X.columns.to_numpy()\n",
    "        self.rejected_columns = []\n",
    "        self.accepted_columns = []\n",
    "\n",
    "        self.check_X()\n",
    "        self.check_missing_values()\n",
    "        self.sample = sample\n",
    "        self.train_or_test = train_or_test\n",
    "        self.stratify = stratify\n",
    "\n",
    "        self.features_to_remove = []\n",
    "        self.hits  = np.zeros(self.ncols)\n",
    "        self.order = self.create_mapping_between_cols_and_indices()\n",
    "        self.create_importance_history()\n",
    "\n",
    "        if self.sample: self.preds = self.isolation_forest(self.X, self.sample_weight)\n",
    "\n",
    "        for trial in tqdm(range(self.n_trials)):\n",
    "\n",
    "            self.remove_features_if_rejected()\n",
    "            self.columns = self.X.columns.to_numpy()\n",
    "            self.create_shadow_features()\n",
    "\n",
    "            # early stopping\n",
    "            if self.X.shape[1] == 0:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "\n",
    "                self.Check_if_chose_train_or_test_and_train_model()\n",
    "\n",
    "                self.X_feature_import, self.Shadow_feature_import = self.feature_importance(normalize=normalize)\n",
    "                self.update_importance_history()\n",
    "                hits = self.calculate_hits()\n",
    "                self.hits += hits\n",
    "                self.history_hits = np.vstack((self.history_hits, self.hits))\n",
    "                self.test_features(iteration=trial+1)\n",
    "\n",
    "        self.store_feature_importance()\n",
    "        self.calculate_rejected_accepted_tentative(verbose=verbose)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.Subset(self)\n",
    "        \n",
    "    def calculate_rejected_accepted_tentative(self, verbose):\n",
    "\n",
    "        \"\"\"\n",
    "        Figures out which features have been either accepted rejeected or tentative\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        3 lists\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.rejected  = list(set(self.flatten_list(self.rejected_columns))-set(self.flatten_list(self.accepted_columns)))\n",
    "        self.accepted  = list(set(self.flatten_list(self.accepted_columns)))\n",
    "        self.tentative = list(set(self.all_columns) - set(self.rejected + self.accepted))\n",
    "\n",
    "        if verbose:\n",
    "            print(str(len(self.accepted))  + ' attributes confirmed important: ' + str(self.accepted))\n",
    "            print(str(len(self.rejected))  + ' attributes confirmed unimportant: ' + str(self.rejected))\n",
    "            print(str(len(self.tentative)) + ' tentative attributes remains: ' + str(self.tentative))\n",
    "\n",
    "\n",
    "\n",
    "    def create_importance_history(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Creates a dataframe object to store historical feature importance scores.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Datframe\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.history_shadow = np.zeros(self.ncols)\n",
    "        self.history_x = np.zeros(self.ncols)\n",
    "        self.history_hits = np.zeros(self.ncols)\n",
    "\n",
    "\n",
    "    def update_importance_history(self):\n",
    "\n",
    "        \"\"\"\n",
    "        At each iteration update the datframe object that stores the historical feature importance scores.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Datframe\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        padded_history_shadow  = np.full((self.ncols), np.NaN)\n",
    "        padded_history_x = np.full((self.ncols), np.NaN)\n",
    "\n",
    "        for (index, col) in enumerate(self.columns):\n",
    "            map_index = self.order[col]\n",
    "            padded_history_shadow[map_index] = self.Shadow_feature_import[index]\n",
    "            padded_history_x[map_index] = self.X_feature_import[index]\n",
    "\n",
    "        self.history_shadow = np.vstack((self.history_shadow, padded_history_shadow))\n",
    "        self.history_x = np.vstack((self.history_x, padded_history_x))\n",
    "\n",
    "\n",
    "\n",
    "    def store_feature_importance(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Reshapes the columns in the historical feature importance scores object also adds the mean, median, max, min\n",
    "        shadow feature scores.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Datframe\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.history_x = pd.DataFrame(data=self.history_x,\n",
    "                                 columns=self.all_columns)\n",
    "\n",
    "\n",
    "        self.history_x['Max_Shadow']    =  [max(i) for i in self.history_shadow]\n",
    "        self.history_x['Min_Shadow']    =  [min(i) for i in self.history_shadow]\n",
    "        self.history_x['Mean_Shadow']   =  [np.nanmean(i) for i in self.history_shadow]\n",
    "        self.history_x['Median_Shadow'] =  [np.nanmedian(i) for i in self.history_shadow]\n",
    "\n",
    "\n",
    "    def results_to_csv(self, filename='feature_importance'):\n",
    "\n",
    "        \"\"\"\n",
    "        Saves the historical feature importance scores to csv.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filname : string\n",
    "            used as the name for the outputed file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        comma delimnated file\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        features = pd.DataFrame(data={'Features':self.history_x.iloc[1:].columns.values,\n",
    "        'Average Feature Importance':self.history_x.iloc[1:].mean(axis=0).values,\n",
    "        'Standard Deviation Importance':self.history_x.iloc[1:].std(axis=0).values})\n",
    "\n",
    "        decision_mapper = self.create_mapping_of_features_to_attribute(maps=['Tentative','Rejected','Accepted', 'Shadow'])\n",
    "        features['Decision'] = features['Features'].map(decision_mapper)\n",
    "        features = features.sort_values(by='Average Feature Importance',ascending=False)\n",
    "\n",
    "        features.to_csv(filename + '.csv', index=False)\n",
    "\n",
    "\n",
    "    def remove_features_if_rejected(self):\n",
    "\n",
    "        \"\"\"\n",
    "        At each iteration if a feature has been rejected by the algorithm remove it from the process\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.features_to_remove) != 0:\n",
    "            for feature in self.features_to_remove:\n",
    "                try:\n",
    "                    self.X.drop(feature, axis = 1, inplace=True)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def average_of_list(lst):\n",
    "        return sum(lst) / len(lst)\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_list(array):\n",
    "        return [item for sublist in array for item in sublist]\n",
    "\n",
    "\n",
    "    def create_mapping_between_cols_and_indices(self):\n",
    "        return dict(zip(self.X.columns.to_list(), np.arange(self.X.shape[1])))\n",
    "\n",
    "\n",
    "    def calculate_hits(self):\n",
    "\n",
    "        \"\"\"\n",
    "        If a features importance is greater than the maximum importance value of all the random shadow\n",
    "        features then we assign it a hit.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Percentile : value ranging from 0-1\n",
    "            can be used to reduce value of the maximum value of the shadow features making the algorithm\n",
    "            more lenient.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        shadow_threshold = np.percentile(self.Shadow_feature_import,\n",
    "                                        self.percentile)\n",
    "\n",
    "        padded_hits = np.zeros(self.ncols)\n",
    "        hits = self.X_feature_import > shadow_threshold\n",
    "\n",
    "        for (index, col) in enumerate(self.columns):\n",
    "            map_index = self.order[col]\n",
    "            padded_hits[map_index] += hits[index]\n",
    "\n",
    "        return padded_hits\n",
    "\n",
    "\n",
    "    def create_shadow_features(self):\n",
    "        \"\"\"\n",
    "        Creates the random shadow features by shuffling the existing columns.\n",
    "\n",
    "        Returns:\n",
    "            Datframe with random permutations of the original columns.\n",
    "        \"\"\"\n",
    "        self.X_shadow = self.X.apply(np.random.permutation)\n",
    "        \n",
    "        if isinstance(self.X_shadow, pd.DataFrame):\n",
    "            # append\n",
    "            obj_col = self.X_shadow.select_dtypes(\"object\").columns.tolist()\n",
    "            if obj_col ==[] :\n",
    "                 pass\n",
    "            else :\n",
    "                 self.X_shadow[obj_col] =self.X_shadow[obj_col].astype(\"category\")\n",
    "\n",
    "        self.X_shadow.columns = ['shadow_' + feature for feature in self.X.columns]\n",
    "        self.X_boruta = pd.concat([self.X, self.X_shadow], axis = 1)\n",
    "\n",
    "        col_types = self.X_boruta.dtypes\n",
    "        self.X_categorical = list(col_types[(col_types=='category' ) | (col_types=='object')].index)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_Zscore(array):\n",
    "        \"\"\"\n",
    "        Calculates the Z-score of an array\n",
    "\n",
    "        Parameters\n",
    "         ----------\n",
    "        array: array_like\n",
    "\n",
    "        Returns:\n",
    "            normalised array\n",
    "        \"\"\"\n",
    "        mean_value = np.mean(array)\n",
    "        std_value  = np.std(array)\n",
    "        return [(element-mean_value)/std_value for element in array]\n",
    "\n",
    "\n",
    "    def feature_importance(self, normalize):\n",
    "\n",
    "        \"\"\"\n",
    "        Caculates the feature importances scores of the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        importance_measure: string\n",
    "            allows the user to choose either the Shap or Gini importance metrics\n",
    "\n",
    "        normalize: boolean\n",
    "            if true the importance values will be normalized using the z-score formula\n",
    "\n",
    "        Returns:\n",
    "            array of normalized feature importance scores for both the shadow and original features.\n",
    "\n",
    "        Raise\n",
    "        ----------\n",
    "            ValueError:\n",
    "                If no Importance measure was specified\n",
    "        \"\"\"\n",
    "\n",
    "        if self.importance_measure == 'shap':\n",
    "\n",
    "            self.explain()\n",
    "            vals = self.shap_values\n",
    "\n",
    "            if normalize:\n",
    "                vals = self.calculate_Zscore(vals)\n",
    "\n",
    "            X_feature_import = vals[:len(self.X.columns)]\n",
    "            Shadow_feature_import = vals[len(self.X_shadow.columns):]\n",
    "            \n",
    "        elif self.importance_measure == 'perm':\n",
    "            \n",
    "            # set default scoring as f1, can be changed to an argument for customizability\n",
    "            perm_importances_ =  permutation_importance(self.model, self.X, self.y, scoring='f1')\n",
    "            perm_importances_ = perm_importance.importances_mean\n",
    "\n",
    "            if normalize:\n",
    "                perm_importances_ = self.calculate_Zscore(perm_importances_)\n",
    "\n",
    "            X_feature_import = perm_importances_[:len(self.X.columns)]\n",
    "            Shadow_feature_import = perm_importances_[len(self.X.columns):]\n",
    "\n",
    "        elif self.importance_measure == 'gini':\n",
    "\n",
    "                feature_importances_ =  np.abs(self.model.feature_importances_)\n",
    "\n",
    "                if normalize:\n",
    "                    feature_importances_ = self.calculate_Zscore(feature_importances_)\n",
    "\n",
    "                X_feature_import = feature_importances_[:len(self.X.columns)]\n",
    "                Shadow_feature_import = feature_importances_[len(self.X.columns):]\n",
    "\n",
    "        else:\n",
    "\n",
    "            raise ValueError('No Importance_measure was specified select one of (shap, perm, gini)')\n",
    "\n",
    "\n",
    "        return X_feature_import, Shadow_feature_import\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def isolation_forest(X, sample_weight):\n",
    "        '''\n",
    "        fits isloation forest to the dataset and gives an anomally score to every sample\n",
    "        '''\n",
    "        clf = IsolationForest().fit(X, sample_weight = sample_weight)\n",
    "        preds = clf.score_samples(X)\n",
    "        return preds\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_5_percent(num):\n",
    "        return round(5  / 100 * num)\n",
    "\n",
    "\n",
    "    def get_5_percent_splits(self, length):\n",
    "        '''\n",
    "        splits dataframe into 5% intervals\n",
    "        '''\n",
    "        five_percent = self.get_5_percent(length)\n",
    "        return np.arange(five_percent,length,five_percent)\n",
    "\n",
    "\n",
    "\n",
    "    def find_sample(self):\n",
    "        '''\n",
    "        Finds a sample by comparing the distributions of the anomally scores between the sample and the original\n",
    "        distribution using the KS-test. Starts of a 5% howver will increase to 10% and then 15% etc. if a significant sample can not be found\n",
    "        '''\n",
    "        loop = True\n",
    "        iteration = 0\n",
    "        size = self.get_5_percent_splits(self.X.shape[0])\n",
    "        element = 1\n",
    "        while loop:\n",
    "\n",
    "            sample_indices = choice(np.arange(self.preds.size),  size=size[element], replace=False)\n",
    "            sample = np.take(self.preds, sample_indices)\n",
    "            if ks_2samp(self.preds, sample).pvalue > 0.95:\n",
    "                break\n",
    "            \n",
    "            iteration+=1\n",
    "\n",
    "            if iteration == 20:\n",
    "                element  += 1\n",
    "                iteration = 0\n",
    "\n",
    "\n",
    "        return self.X_boruta.iloc[sample_indices]\n",
    "\n",
    "\n",
    "\n",
    "    def explain(self):\n",
    "\n",
    "        \"\"\"\n",
    "        The shap package has numerous variants of explainers which use different assumptions depending on the model\n",
    "        type this function allows the user to choose explainer\n",
    "\n",
    "        Returns:\n",
    "            shap values\n",
    "\n",
    "        Raise\n",
    "        ----------\n",
    "            ValueError:\n",
    "                if no model type has been specified tree as default\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        explainer = shap.TreeExplainer(self.model, \n",
    "                                       feature_perturbation = \"tree_path_dependent\",\n",
    "                                       approximate = True)\n",
    "\n",
    "\n",
    "        if self.sample:\n",
    "\n",
    "\n",
    "            if self.classification:\n",
    "                # for some reason shap returns values wraped in a list of length 1\n",
    "\n",
    "                self.shap_values = np.array(explainer.shap_values(self.find_sample()))\n",
    "                if isinstance(self.shap_values, list):\n",
    "\n",
    "                    class_inds = range(len(self.shap_values))\n",
    "                    shap_imp = np.zeros(self.shap_values[0].shape[1])\n",
    "                    for i, ind in enumerate(class_inds):\n",
    "                        shap_imp += np.abs(self.shap_values[ind]).mean(0)\n",
    "                    self.shap_values /= len(self.shap_values)\n",
    "\n",
    "                elif len(self.shap_values.shape) == 3:\n",
    "                    self.shap_values = np.abs(self.shap_values).sum(axis=0)\n",
    "                    self.shap_values = self.shap_values.mean(0)\n",
    "\n",
    "                else:\n",
    "                    self.shap_values = np.abs(self.shap_values).mean(0)\n",
    "\n",
    "            else:\n",
    "                self.shap_values = explainer.shap_values(self.find_sample())\n",
    "                self.shap_values = np.abs(self.shap_values).mean(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if self.classification:\n",
    "                # for some reason shap returns values wraped in a list of length 1\n",
    "                self.shap_values = np.array(explainer.shap_values(self.X_boruta))\n",
    "                if isinstance(self.shap_values, list):\n",
    "\n",
    "                    class_inds = range(len(self.shap_values))\n",
    "                    shap_imp = np.zeros(self.shap_values[0].shape[1])\n",
    "                    for i, ind in enumerate(class_inds):\n",
    "                        shap_imp += np.abs(self.shap_values[ind]).mean(0)\n",
    "                    self.shap_values /= len(self.shap_values)\n",
    "\n",
    "                elif len(self.shap_values.shape) == 3:\n",
    "                    self.shap_values = np.abs(self.shap_values).sum(axis=0)\n",
    "                    self.shap_values = self.shap_values.mean(0)\n",
    "\n",
    "                else:\n",
    "                    self.shap_values = np.abs(self.shap_values).mean(0)\n",
    "\n",
    "            else:\n",
    "                self.shap_values = explainer.shap_values(self.X_boruta)\n",
    "                self.shap_values = np.abs(self.shap_values).mean(0)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def binomial_H0_test(array, n, p, alternative):\n",
    "        \"\"\"\n",
    "        Perform a test that the probability of success is p.\n",
    "        This is an exact, two-sided test of the null hypothesis\n",
    "        that the probability of success in a Bernoulli experiment is p\n",
    "        \"\"\"\n",
    "        return [binomtest(x, n=n, p=p, alternative=alternative).pvalue for x in array]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def symetric_difference_between_two_arrays(array_one, array_two):\n",
    "        set_one = set(array_one)\n",
    "        set_two = set(array_two)\n",
    "        return np.array(list(set_one.symmetric_difference(set_two)))\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def find_index_of_true_in_array(array):\n",
    "        length = len(array)\n",
    "        return list(filter(lambda x: array[x], range(length)))\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def bonferoni_corrections(pvals, alpha=0.05, n_tests=None):\n",
    "        \"\"\"\n",
    "        used to counteract the problem of multiple comparisons.\n",
    "        \"\"\"\n",
    "        pvals = np.array(pvals)\n",
    "\n",
    "        if n_tests is None:\n",
    "            n_tests = len(pvals)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        alphacBon = alpha / float(n_tests)\n",
    "        reject = pvals <= alphacBon\n",
    "        pvals_corrected = pvals * float(n_tests)\n",
    "        return reject, pvals_corrected\n",
    "\n",
    "\n",
    "    def test_features(self, iteration):\n",
    "\n",
    "        \"\"\"\n",
    "        For each feature with an undetermined importance perform a two-sided test of equality\n",
    "        with the maximum shadow value to determine if it is statistcally better\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hits: an array which holds the history of the number times\n",
    "              this feature was better than the maximum shadow\n",
    "\n",
    "        Returns:\n",
    "            Two arrays of the names of the accepted and rejected columns at that instance\n",
    "        \"\"\"\n",
    "        \n",
    "        hits = self.hits.astype(int)\n",
    "        acceptance_p_values = self.binomial_H0_test(hits,\n",
    "                                                    n=iteration,\n",
    "                                                    p=0.5,\n",
    "                                                    alternative='greater')\n",
    "\n",
    "        regect_p_values = self.binomial_H0_test(hits,\n",
    "                                                n=iteration,\n",
    "                                                p=0.5,\n",
    "                                                alternative='less')\n",
    "\n",
    "        # [1] as function returns a tuple\n",
    "        modified_acceptance_p_values = self.bonferoni_corrections(acceptance_p_values,\n",
    "                                                                  alpha=0.05,\n",
    "                                                                  n_tests=len(self.columns))[1]\n",
    "\n",
    "        modified_regect_p_values = self.bonferoni_corrections(regect_p_values,\n",
    "                                                              alpha=0.05,\n",
    "                                                              n_tests=len(self.columns))[1]\n",
    "\n",
    "        # Take the inverse as we want true to keep featrues\n",
    "        rejected_columns = np.array(modified_regect_p_values) < self.pvalue\n",
    "        accepted_columns = np.array(modified_acceptance_p_values) < self.pvalue\n",
    "\n",
    "        rejected_indices = self.find_index_of_true_in_array(rejected_columns)\n",
    "        accepted_indices = self.find_index_of_true_in_array(accepted_columns)\n",
    "\n",
    "        rejected_features = self.all_columns[rejected_indices]\n",
    "        accepted_features = self.all_columns[accepted_indices]\n",
    "\n",
    "\n",
    "        self.features_to_remove = rejected_features\n",
    "\n",
    "\n",
    "        self.rejected_columns.append(rejected_features)\n",
    "        self.accepted_columns.append(accepted_features)\n",
    "\n",
    "\n",
    "    def TentativeRoughFix(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Sometimes no matter how many iterations are run a feature may neither be rejected or\n",
    "        accepted. This method is used in this case to make a decision on a tentative feature\n",
    "        by comparing its median importance value with the median max shadow value.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tentative: an array which holds the names of the tentative attiributes.\n",
    "\n",
    "        Returns:\n",
    "            Two arrays of the names of the final decision of the accepted and rejected columns.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        median_tentaive_values = self.history_x[self.tentative].median(axis=0).values\n",
    "        median_max_shadow = self.history_x['Max_Shadow'].median(axis=0)\n",
    "\n",
    "\n",
    "        filtered = median_tentaive_values > median_max_shadow\n",
    "\n",
    "        self.tentative = np.array(self.tentative)\n",
    "        newly_accepted = self.tentative[filtered]\n",
    "\n",
    "        if len(newly_accepted) < 1:\n",
    "            newly_rejected = self.tentative\n",
    "\n",
    "        else:\n",
    "            newly_rejected = self.symetric_difference_between_two_arrays(newly_accepted, self.tentative)\n",
    "\n",
    "        print(str(len(newly_accepted)) + ' tentative features are now accepted: ' + str(newly_accepted))\n",
    "        print(str(len(newly_rejected)) + ' tentative features are now rejected: ' + str(newly_rejected))\n",
    "\n",
    "        self.rejected = self.rejected + newly_rejected.tolist()\n",
    "        self.accepted = self.accepted + newly_accepted.tolist()\n",
    "\n",
    "\n",
    "\n",
    "    def Subset(self, tentative=False):\n",
    "        \"\"\"\n",
    "        Returns the subset of desired features\n",
    "        \"\"\"\n",
    "        if tentative:\n",
    "            return self.starting_X[self.accepted + list(self.tentative)]\n",
    "        else:\n",
    "            return self.starting_X[self.accepted]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create_list(array, color):\n",
    "        colors = [color for x in range(len(array))]\n",
    "        return colors\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_data(data, column, value):\n",
    "        data = data.copy()\n",
    "        return data.loc[(data[column] == value) | (data[column] == 'Shadow')]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def hasNumbers(inputString):\n",
    "        return any(char.isdigit() for char in inputString)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def check_if_which_features_is_correct(my_string):\n",
    "\n",
    "        my_string = str(my_string).lower()\n",
    "        if my_string in ['tentative','rejected','accepted','all']:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise ValueError(my_string + \" is not a valid value did you mean to type 'all', 'tentative', 'accepted' or 'rejected' ?\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot(self, X_rotation=90, X_size=8, figsize=(12,8),\n",
    "            y_scale='log', which_features='all', display=True):\n",
    "\n",
    "        \"\"\"\n",
    "        creates a boxplot of the feature importances\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_rotation: int\n",
    "            Controls the orientation angle of the tick labels on the X-axis\n",
    "\n",
    "        X_size: int\n",
    "            Controls the font size of the tick labels\n",
    "\n",
    "        y_scale: string\n",
    "            Log transform of the y axis scale as hard to see the plot as it is normally dominated by two or three\n",
    "            features.\n",
    "\n",
    "        which_features: string\n",
    "            Despite efforts if the number of columns is large the plot becomes cluttered so this parameter allows you to\n",
    "            select subsets of the features like the accepted, rejected or tentative features default is all.\n",
    "\n",
    "        Display: Boolean\n",
    "        controls if the output is displayed or not, set to false when running test scripts\n",
    "\n",
    "        \"\"\"\n",
    "        # data from wide to long\n",
    "        data = self.history_x.iloc[1:]\n",
    "        data['index'] = data.index\n",
    "        data = pd.melt(data, id_vars='index', var_name='Methods')\n",
    "\n",
    "        decision_mapper = self.create_mapping_of_features_to_attribute(maps=['Tentative','Rejected','Accepted', 'Shadow'])\n",
    "        data['Decision'] = data['Methods'].map(decision_mapper)\n",
    "        data.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        options = { 'accepted' : self.filter_data(data,'Decision', 'Accepted'),\n",
    "                    'tentative': self.filter_data(data,'Decision', 'Tentative'),\n",
    "                    'rejected' : self.filter_data(data,'Decision', 'Rejected'),\n",
    "                    'all' : data\n",
    "                    }\n",
    "\n",
    "        self.check_if_which_features_is_correct(which_features)\n",
    "        data = options[which_features.lower()]\n",
    "\n",
    "        self.box_plot(data=data,\n",
    "                      X_rotation=X_rotation,\n",
    "                      X_size=X_size,\n",
    "                      y_scale=y_scale,\n",
    "                      figsize=figsize)\n",
    "        if display:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def box_plot(self, data, X_rotation, X_size, y_scale, figsize):\n",
    "\n",
    "        if y_scale=='log':\n",
    "            minimum = data['value'].min()\n",
    "            if minimum <= 0:\n",
    "                data['value'] += abs(minimum) + 0.01\n",
    "\n",
    "        order = data.groupby(by=[\"Methods\"])[\"value\"].mean().sort_values(ascending=False).index\n",
    "        my_palette = self.create_mapping_of_features_to_attribute(maps= ['yellow','red','green','blue'])\n",
    "\n",
    "        # Use a color palette\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = sns.boxplot(x=data[\"Methods\"], y=data[\"value\"],\n",
    "                        order=order, palette=my_palette)\n",
    "\n",
    "        if y_scale == 'log':ax.set(yscale=\"log\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=X_rotation, size=X_size)\n",
    "        ax.set_title('Feature Importance')\n",
    "        ax.set_ylabel('Z-Score')\n",
    "        ax.set_xlabel('Features')\n",
    "\n",
    "\n",
    "    def create_mapping_of_features_to_attribute(self, maps = []):\n",
    "\n",
    "        rejected = list(self.rejected)\n",
    "        tentative = list(self.tentative)\n",
    "        accepted = list(self.accepted)\n",
    "        shadow = ['Max_Shadow','Median_Shadow','Min_Shadow','Mean_Shadow']\n",
    "\n",
    "        tentative_map = self.create_list(tentative, maps[0])\n",
    "        rejected_map  = self.create_list(rejected, maps[1])\n",
    "        accepted_map  = self.create_list(accepted, maps[2])\n",
    "        shadow_map = self.create_list(shadow, maps[3])\n",
    "\n",
    "        values = tentative_map + rejected_map + accepted_map + shadow_map\n",
    "        keys = tentative + rejected + accepted + shadow\n",
    "\n",
    "        return self.to_dictionary(keys, values)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def to_dictionary(list_one, list_two):\n",
    "        return dict(zip(list_one, list_two))\n",
    "\n",
    "\n",
    "\n",
    "def load_data(data_type='classification'):\n",
    "\n",
    "    \"\"\"\n",
    "    Load Example datasets for the user to try out the package\n",
    "    \"\"\"\n",
    "\n",
    "    data_type = data_type.lower()\n",
    "\n",
    "    if data_type == 'classification':\n",
    "        cancer = load_breast_cancer()\n",
    "        X = pd.DataFrame(np.c_[cancer['data'], cancer['target']], columns = np.append(cancer['feature_names'], ['target']))\n",
    "        y = X.pop('target')\n",
    "\n",
    "    elif data_type == 'regression':\n",
    "        diabetes = load_diabetes()\n",
    "        X = pd.DataFrame(np.c_[diabetes['data'], diabetes['target']], columns = np.append(diabetes['feature_names'], ['target']))\n",
    "        y = X.pop('target')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"No data_type was specified, use either 'classification' or 'regression'\")\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
